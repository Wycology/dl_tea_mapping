{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5n57cb54THwaXOBRA6xTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wycology/dl_tea_mapping/blob/main/dl_tea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='green'><b> SATELLITE DATA FOR AGRICULTURAL ECONOMISTS</b></font>\n",
        "\n",
        "\n",
        "<font color='blue'><b>THEORY AND PRACTICE</b></font>\n",
        "\n",
        "**Mapping tea plantations in Central Kenya: _Deep Learning Approach_**\n",
        "\n",
        "\n",
        "*David Wuepper, Lisa Biber-Freudenberger, Hadi, Wyclife Agumba Oluoch*\n",
        "\n",
        "[Land Economics Group](https://www.ilr1.uni-bonn.de/en/research/research-groups/land-economics), University of Bonn, Bonn, Germany\n",
        "\n",
        "---\n",
        "\n",
        "# **Background**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TkemFw3E0WAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we introduce basics of using deep learning approach to segment tea fields with a practical example at the foot of Mount Kenya. We obtained high resolution Sentinel-2 satellite image from [Google Earth Engine](https://code.earthengine.google.com/60cf3e783458009bd8378eaded30f5c7). On the other hand, we obtained labels by manually digitizing tea plantations within QGIS using Google Satellite Hybrid basemap. The labels cover a small portion of the downloaded Satellite image so that we can train the model and use it to segment tea fields elsewhere.\n",
        "We used torchgeo for this modeling task due to the following reasons:\n",
        "1. It is simple to use, eliminating a lot of issues such as georeferencing, chipping, label creation.\n",
        "2. It also maximally obtain training samples from the region of interest."
      ],
      "metadata": {
        "id": "UoK9t_IT0d7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries\n",
        "---\n",
        "Since `torchgeo` is not natively installed in colab, we will have to install it. We will also install `torchseg` to help with the segmentation work. Other supporting libraries will just be imported as they are already pre-installed in colab."
      ],
      "metadata": {
        "id": "_jd9jmSt0iue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries not already available in colab\n",
        "!pip install torchgeo\n",
        "!pip install torchseg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ikM6_Uno0cQD",
        "outputId": "eb0a431e-32cd-497a-9307-0b7c7164bcc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchgeo\n",
            "  Downloading torchgeo-0.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (0.8.1)\n",
            "Collecting fiona>=1.8.22 (from torchgeo)\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia>=0.7.4 (from torchgeo)\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lightly!=1.4.26,>=1.4.5 (from torchgeo)\n",
            "  Downloading lightly-1.5.20-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting lightning!=2.3.*,!=2.5.0,>=2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.2 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (11.2.1)\n",
            "Requirement already satisfied: pyproj>=3.4 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (3.7.1)\n",
            "Collecting rasterio!=1.4.0,!=1.4.1,!=1.4.2,>=1.3.3 (from torchgeo)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting rtree>=1.0.1 (from torchgeo)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting segmentation-models-pytorch>=0.3.3 (from torchgeo)\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shapely>=1.8.5 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.1.0)\n",
            "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (1.0.15)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.6.0+cu124)\n",
            "Collecting torchmetrics>=1.2 (from torchgeo)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchvision>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (0.21.0+cu124)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (4.13.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.22->torchgeo) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.22->torchgeo) (2025.4.26)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.22->torchgeo) (8.1.8)\n",
            "Collecting click-plugins>=1.0 (from fiona>=1.8.22->torchgeo)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona>=1.8.22->torchgeo)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia>=0.7.4->torchgeo)\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia>=0.7.4->torchgeo) (24.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (4.67.1)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.11.4)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.4.0)\n",
            "Collecting aenum>=3.1.11 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2025.3.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jsonargparse<5.0,>=4.27.7 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading jsonargparse-4.39.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting omegaconf<3.0,>=2.2.3 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.11/dist-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (13.9.4)\n",
            "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting bitsandbytes<1.0,>=0.45.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->torchgeo) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->torchgeo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->torchgeo) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->torchgeo) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->torchgeo) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->torchgeo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->torchgeo) (2025.2)\n",
            "Collecting affine (from rasterio!=1.4.0,!=1.4.1,!=1.4.2,>=1.3.3->torchgeo)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch>=0.3.3->torchgeo) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch>=0.3.3->torchgeo) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchgeo)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchgeo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchgeo) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.11.15)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (75.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.10)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.19.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (5.29.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchgeo) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.5.2)\n",
            "Downloading torchgeo-0.7.0-py3-none-any.whl (604 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.0/605.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.20-py3-none-any.whl (851 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.6/851.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.39.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=1d6e2b4649123eda5cb39b6bf1f6767bd4feb04b4bb46c64168c7a2675ad4455\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, typeshed-client, tensorboardX, rtree, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, lightly_utils, kornia_rs, jsonargparse, cligj, click-plugins, affine, rasterio, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, fiona, nvidia-cusolver-cu12, torchmetrics, kornia, bitsandbytes, pytorch_lightning, segmentation-models-pytorch, lightning, lightly, torchgeo\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aenum-3.1.16 affine-2.4.0 antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.5 click-plugins-1.1.1 cligj-0.7.2 fiona-1.10.1 hydra-core-1.3.2 jsonargparse-4.39.0 kornia-0.8.0 kornia_rs-0.1.9 lightly-1.5.20 lightly_utils-0.0.2 lightning-2.5.1.post0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 pytorch_lightning-2.5.1.post0 rasterio-1.4.3 rtree-1.4.0 segmentation-models-pytorch-0.5.0 tensorboardX-2.6.2.2 torchgeo-0.7.0 torchmetrics-1.7.1 typeshed-client-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "984bb30c1e2d448e9aac638e1a597b14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchseg\n",
            "  Downloading torchseg-0.0.1a4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchseg) (0.8.1)\n",
            "Requirement already satisfied: timm>=0.9.12 in /usr/local/lib/python3.11/dist-packages (from torchseg) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from torchseg) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.12->torchseg) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.12->torchseg) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.12->torchseg) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.12->torchseg) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchseg) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->torchseg) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.9.12->torchseg) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.9.12->torchseg) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.9.12->torchseg) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->torchseg) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.12->torchseg) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.12->torchseg) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.12->torchseg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.12->torchseg) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.12->torchseg) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.12->torchseg) (2025.4.26)\n",
            "Downloading torchseg-0.0.1a4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchseg\n",
            "Successfully installed torchseg-0.0.1a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import json\n",
        "import torch\n",
        "import rasterio\n",
        "import torchseg\n",
        "import torchgeo\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchgeo.transforms import AppendNDVI\n",
        "from rasterio.transform import from_bounds\n",
        "from torchgeo.samplers import RandomGeoSampler, GridGeoSampler\n",
        "from torchgeo.datasets import VectorDataset, RasterDataset, stack_samples"
      ],
      "metadata": {
        "id": "EPvUqX9Z0mny"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the libraries, we make an important step of confirming the working directory. This is important since both our image and gpkg will be read from this location so we need to be sure of the path. We can use `pwd` function to print it."
      ],
      "metadata": {
        "id": "jcnZD7xt0ty0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # Confirm the working directory"
      ],
      "metadata": {
        "id": "Dg5Z4M1-0rN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Dataset\n",
        "---\n",
        "With `torchgeo`, we do not have to pre-chip the satellite image into small chips of say 256 by 256 pixels. This it achieves on the fly. However, we need to tell it the path to where our satellite image is. In fact, we can have several large images here. For now, it is the only _.tif_ image our working directory, wo we define the class as follows:"
      ],
      "metadata": {
        "id": "hRrZylsA0zhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GeoTiff dataset class\n",
        "\n",
        "class GeoTiffDataset(RasterDataset):\n",
        "  filename_glob = \"*.tif\"\n",
        "raster_data = GeoTiffDataset(paths = \"/content\")"
      ],
      "metadata": {
        "id": "VBq6ifSE0rKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In that case, raster_data is a blueprint of the satellite image we have in the directory. Next, we do the same for the label data. This label data is a _.gpkg_ file which has a column stating the identity of the each polygon as either tea or not tea. In other words, the class column. Here, we call the class column as `tea_no_tea`. This is very important as it is what the library uses to create a label binary layer under the hood to intersect with the satellite image. We achieve this as follows:"
      ],
      "metadata": {
        "id": "gASRx2B-05QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the label (here vector but can also be mask raster) dataset class.\n",
        "# Remember to include label name. Never forget this!\n",
        "\n",
        "class LabelDataset(VectorDataset):\n",
        "  filename_glob = \"*.gpkg\"\n",
        "label_data = LabelDataset(paths = \"/content\", label_name = \"tea_no_tea\")"
      ],
      "metadata": {
        "id": "NGv90kvA0rHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining raster_data and label_data\n",
        "\n",
        "Now that we have blueprints of both raster_data and label_data, the next step is to intersect the two. This will behave like _cropping_ or _clipping_ the raster to the extent of the label_data. This is the reason why we are not worried that the raster extent is bigger than the label extent. Chips for training the model will only be ontained from where the two datasets intersect/overlap. Regions outside the label_data will not be sampled. As simple as it can get, we achieve this intersection using an _&_ operator."
      ],
      "metadata": {
        "id": "GXrnN5391E1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the intersection of the raster and vector/label datasets\n",
        "\n",
        "training_data = raster_data & label_data"
      ],
      "metadata": {
        "id": "_skUtBwb0rEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You notice the printout that **Converting LabelDataset res from (0.0001, 0.0001) to (10.0, 10.0)**. This tells us that our vector label data with polygons has now been converted to a binary raster under the hood with a pixel size similar to that of the satellite image we have - Sentinel-2. Something imortant to note also is that the pixels in both layers has been **aligned**."
      ],
      "metadata": {
        "id": "r5gzrFam1La-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append variables derivable from the bands, such as NDVI\n",
        "\n",
        "append_ndvi = AppendNDVI(index_nir = 7, index_red = 3)"
      ],
      "metadata": {
        "id": "rvwGiMLA0rAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sampler that will execute the task of extracting labels\n",
        "\n",
        "sampler = RandomGeoSampler(dataset = training_data, size = 32, length = 1000)"
      ],
      "metadata": {
        "id": "7C7LvsPL0q9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a customized collate function to append NDVI to the sampled images\n",
        "def custom_collate_fn(samples):\n",
        "  for sample in samples:\n",
        "    sample[\"image\"] = append_ndvi(sample[\"image\"])[0]\n",
        "  return stack_samples(samples)"
      ],
      "metadata": {
        "id": "PYQvKVsC0q5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dataloader. This is the function that will be serving the role of availing batches of extracted samples for model training\n",
        "dataloader = DataLoader(\n",
        "    dataset = training_data,\n",
        "    batch_size = 50,\n",
        "    sampler = sampler,\n",
        "    collate_fn = custom_collate_fn # normally would be stack_samples\n",
        ")"
      ],
      "metadata": {
        "id": "1vSP5CIt1X5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the dataloader to confirm that it is able to load the data\n",
        "\n",
        "for batch in dataloader:\n",
        "  image = batch[\"image\"][:, :12, :, :]\n",
        "  mask = image[:, -1, :, :]\n",
        "\n",
        "  print(f\"Image batch length: {len(image)}\")\n",
        "  print(f\"Mask batch length: {len(mask)}\")\n",
        "  break"
      ],
      "metadata": {
        "id": "AvP_3oAi1X2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use Unet model from torchseg. Which is pretrained so we do not need to build it from scratch\n",
        "model = torchseg.Unet(\n",
        "    encoder_name = \"resnet18\",\n",
        "    encoder_weights = False,\n",
        "    in_channels = 11,\n",
        "    classes = 2\n",
        ")"
      ],
      "metadata": {
        "id": "99g0hQ-h1Xzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cuda if available, otherwise cpu\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "EqMhnBGG1XwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = -1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "gVGGo31n1j0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "metrics = {\"loss\": [], \"accuracy\": []}\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "yQK1Wzto1jw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_pixels = 0\n",
        "\n",
        "  with tqdm(dataloader, desc = f\"Epoch {epoch + 1} / {num_epochs}\") as pbar:\n",
        "    for batch in pbar:\n",
        "      images = batch[\"image\"][:, :12, :, :].to(device)\n",
        "      masks = batch[\"mask\"].to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, masks.long())\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      preds = torch.argmax(outputs, dim = 1)\n",
        "      total_correct += (preds == masks).sum().item()\n",
        "      total_pixels += masks.numel()\n",
        "\n",
        "      pbar.set_postfix(loss = loss.item())\n",
        "\n",
        "  epoch_accuracy = total_correct / total_pixels * 100\n",
        "  metrics[\"loss\"].append(epoch_loss)\n",
        "  metrics[\"accuracy\"].append(epoch_accuracy)\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "  # Save training metrics\n",
        "  with open(\"/content/training_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f)\n",
        "\n",
        "  print(\"Training metrics saved to '/content/training_metrics.json\")\n"
      ],
      "metadata": {
        "id": "4l08G_R41jtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training metrics from JSON file\n",
        "with open(\"/content/training_metrics.json\", \"r\") as f:\n",
        "    metrics = json.load(f)\n",
        "\n",
        "# Extract loss and accuracy values\n",
        "loss_values = metrics[\"loss\"]\n",
        "accuracy_values = metrics[\"accuracy\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# Create the plots\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Plot loss\n",
        "ax1.set_xlabel(\"Epochs\")\n",
        "ax1.set_ylabel(\"Loss\", color=\"tab:red\")\n",
        "ax1.plot(epochs, loss_values, label=\"Loss\", color=\"tab:red\")\n",
        "ax1.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
        "\n",
        "# Create a second y-axis for accuracy\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"Accuracy (%)\", color=\"tab:blue\")\n",
        "ax2.plot(epochs, accuracy_values, label=\"Accuracy\", color=\"tab:blue\")\n",
        "ax2.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title(\"Training Loss & Accuracy Over Epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h13n9smM1q69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model.eval()\n",
        "\n",
        "# Path to your input raster\n",
        "raster_path = \"/content/s2_d.tif\"\n",
        "output_path = \"/content/predicted_output.tif\"\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Read the raster file\n",
        "with rasterio.open(raster_path) as src:\n",
        "    image = src.read()  # Shape: (bands, height, width)\n",
        "    transform = src.transform\n",
        "    crs = src.crs\n",
        "    profile = src.profile\n",
        "\n",
        "# Get original height and width\n",
        "orig_h, orig_w = image.shape[1], image.shape[2]\n",
        "\n",
        "# Compute padding needed\n",
        "pad_h = (32 - (orig_h % 32)) % 32  # Ensure divisibility by 32\n",
        "pad_w = (32 - (orig_w % 32)) % 32\n",
        "\n",
        "# Pad image (bottom, right)\n",
        "image_padded = np.pad(image, ((0, 0), (0, pad_h), (0, pad_w)), mode='reflect')\n",
        "\n",
        "# Convert to tensor and move to device\n",
        "image_tensor = torch.tensor(image_padded, dtype=torch.float32).unsqueeze(0).to(device)  # (1, bands, H, W)\n",
        "\n",
        "# Run the model\n",
        "with torch.no_grad():\n",
        "    output = model(image_tensor)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "pred_mask_padded = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()  # (H, W)\n",
        "\n",
        "# Remove padding to match original shape\n",
        "pred_mask = pred_mask_padded[:orig_h, :orig_w]\n",
        "\n",
        "# Save the output raster\n",
        "profile.update(dtype=rasterio.uint8, count=1, height=orig_h, width=orig_w, nodata = 0)  # Update metadata\n",
        "\n",
        "with rasterio.open(output_path, \"w\", **profile) as dst:\n",
        "    dst.write(pred_mask.astype(rasterio.uint8), 1)\n",
        "\n",
        "print(f\"Prediction saved at {output_path}\")\n"
      ],
      "metadata": {
        "id": "IrISlG1g1q3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the predicted output\n",
        "output_path = \"/content/predicted_output.tif\"\n",
        "\n",
        "# Read the predicted raster\n",
        "with rasterio.open(output_path) as src:\n",
        "    pred_mask = src.read(1)  # Read the first (and only) band\n",
        "\n",
        "# Plot the predicted mask\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(pred_mask, cmap=\"gray\")  # Use \"gray\" or \"viridis\" for better contrast\n",
        "plt.colorbar(label=\"Class Label\")\n",
        "plt.title(\"Predicted Segmentation Mask\")\n",
        "plt.axis(\"off\")  # Hide axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eCMeFvB51qz3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}